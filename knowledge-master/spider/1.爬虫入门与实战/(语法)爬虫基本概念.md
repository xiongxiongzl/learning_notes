# 爬虫学习使用指南---爬虫基本 概念

> Auth: 王海飞
>
> Data：2019-01-09
>
> Email：779598160@qq.com
>
> github：https://github.com/coco369/knowledge 



### 前言

网络爬虫（Web Spider。又被称为网页蜘蛛。网络机器人，又称为网页追逐者），是一种依照一定的规则，自己主动的抓取万维网信息的程序或者脚本。另外一些不常使用的名字还有蚂蚁，自己主动索引。模拟程序或者蠕虫。假设把互联网比喻成一个蜘蛛网，那么Spider就是在网上爬来爬去的蜘蛛。

网络蜘蛛是通过网页的链接地址来寻找网页的。从站点某一个页面（一般是首页）開始，读取网页的内容。找到在网页中的其他链接地址。然后通过这些链接地址寻找下一个网页。这样一直循环下去，直到把这个站点全部的网页都抓取完为止。假设把整个互联网当成一个站点。那么网络蜘蛛就能够用这个原理把互联网上全部的网页都抓取下来。这样看来，网络爬虫就是一个爬行程序，一个抓取网页的程序。

<b>简单地说，网络爬虫的基本任务就是抓取网页内容。</b>



#### HTTP基础概念

爬虫中需要掌握如下概念：URL和URI、超文本、HTTP和HTTPS、HTTP请求头、HTTP请求体、响应、响应体、回话与Cookie、代理。

#### 1. URL和URI

URI (Uniform Resource Identifier) 统⼀一资源标志符 URL(Universal Resource Locator) 统⼀一资源定位符 

URL是URI的⼦子集， URI还包括⼀一个⼦子类URN (Universal Resource Name) 统⼀一资源名称，URN 只命名资源不不指定如何定位资源。 

#### 2. 超⽂文本 (hypertext) 

超文本标记语言即为⽹⻚源代码

查看源代码工具：通过浏览器对开发者工具即可查看到当前页面的源码。

#### 3. HTTP和HTTPS
 HTTP (Hyper Text Transfer Protocol) 

超⽂文本传输协议 

HTTPS (Hyper Text Transfer Protocol over Secure Socket Layer)
HTTP加⼊入SSL层，传输内容通过SSL加密
安全通道保证数据传输安全
确认⽹网站真实性

#### 4. HTTP请求过程

用浏览器器开发者⼯工具观察⽹网络请求过程 

##### 4.1 请求 

请求⽅方法 (Request Method) 

```
1. GET请求的参数直接在URL⾥里里，HTTP协议本身对GET请求传递到参数的长度没有限制，但不同的浏览器会对GET请求传递的参数的长度有所限制。

2. POST请求数据⼀一般通过表单提交，提交的数据不会出现在URL里且上传的数据大小没有限制。
```

##### 4.2 请求头 

###### Cache-Control

​        指定了了服务器器和客户端在交互时遵循的缓存机制，即是否要留留下缓存⻚页⾯面数据。
⼀一般在使⽤用浏览器器访问时，都会在计算机本地留留下缓存⻚页⾯面，相当于是浏览器器中的⻚页⾯面保存和
下载选项。但是爬⾍虫就是为了了从⽹网络上爬取数据，所以⼏几乎不不会从缓存中读取数据。所以在设置的时候要侧重从服务器器请求数据⽽而⾮非加载缓存。

* no-cache:客户端告诉服务器器，⾃自⼰己不不要读取缓存，要向服务器器发起请求 
* no-store:同时也是响应头的参数，请求和响应都禁⽌止缓存，即不不存储
*  max-age=0:表示当访问过此⽹网⻚页后的多少秒内再次访问，只加载缓存，⽽而不不去服务器器请 求，在爬⾍虫时⼀一般就写0秒 ⼀一般爬⾍虫就使⽤用以上⼏几个参数，其他的参数都是接受缓存的，所以就不不列列出了了。 
* User-Agent
   中⽂文名⽤用户代理理，服务器器从此处知道客户端的 操作系统类型和版本，电脑CPU类型，浏览器器 种类版本，浏览器器渲染引擎，等等。这是爬⾍虫当中最最重要的⼀一个请求头参数，所以⼀一定要伪 造，甚⾄至多个。如果不不进⾏行行伪造，⽽而直接使⽤用各种爬⾍虫框架中⾃自定义的user-agent，很容易易被 封禁。举例例:
   User-Agent: Mozilla/5.0 (X11; Linux x86_64; rv:52.0) Gecko/20100101 Firefox/52.0 User-Agent: Mozilla/5.0 (Windows NT 6.3; WOW64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/52.0.2743.116 Safari/537.36 

###### Accept 

​        指定客户端可以接受的内容类型，⽐比如⽂文本，图⽚片，应⽤用等等，内容的先后排序表示客户端接 收的先后次序，每种类型之间⽤用逗号隔开。
 其中，对于每⼀一种内容类型，分号 ; 后⾯面会加⼀一个 q=0.6 这样的 q 值，表示该种类型被客户端 喜欢接受的程度，如果没有表示 q=1，数值越⾼高，客户端越喜欢这种类型。 爬⾍虫的时候，⼀一般会伪造若⼲干，将想要找的⽂文字，图⽚片放在前⾯面，其他的放在后⾯面，最后⼀一定 加上/;q=0.8。 

* ⽐如Accept: imagegif,imagex-xbitmap,imagejpeg,applicationx-shockwave- flash,applicationvnd.ms-excel,applicationvnd.ms-powerpoint,applicationmsword, textxml,textshtml:⽂文本类型，斜杠后表示⽂文档的类型，xml，或者shtml applicationxml,applicationxhtml+xml:应⽤用类型，后⾯面表示⽂文档类型,⽐比如 flash动画，excel 表格等等 

* imagegif,imagex-xbitmap:图⽚片类型，表示接收何种类型的图⽚片 /:表示接收任何类型，但是这⼀一条⼀一般写在最后，表示优先接收前⾯面规定的类型，然后再加 载其他类型。 

* Accept-Language 

​        客户端可以接受的语⾔言类型，参数值规范和 accept的很像。⼀一般就接收中⽂文和英⽂文，有其他 语⾔言需求⾃自⾏行行添加。⽐比如:

* Accept-Language: zh-CN,zh;q=0.8,en-US;q=0.6,en;q=0.4

```
zh-CN:中⽂文简体⼤大陆?
zh:其他中⽂文 
en-US:英语美语 
en:其他英语 
```

###### Accept-Encoding 

客户端接收编码类型，⼀些网络压缩格式: Accept-Encoding: gzip, deflate, sdch。相对来说，deflate是⼀一种过时的压缩格式，现在常⽤用 的是gzip 

###### Accept-Charset 

指规定好服务器器处理理表单数据所接受的字符集，也就是说，客户端浏览器器告诉服务器器⾃自⼰己 的表单数据的字符集类型。若没有定义，则默认值为“unknown”。如果服务器器 没有包含此种字符集，就⽆无法正确接收。⼀一般情况下，在爬⾍虫时不不定义该属性，如果定义，例例 ⼦子如下: 

Accept-Charset:gb2312,gbk;q=0.7,utf-8;q=0.7,*;q=0.7 

###### Referer 

浏览器器上次访问的⽹网⻚页url，uri。由于http协议的⽆无记忆性，服务器器可从这⾥里里了了解到客户端访 问的前后路路径，并做⼀一些判断，如果后一次访问的 url 不能从前⼀次访问的⻚页⾯面上跳转获得， 在⼀定程度上说明了了请求头有可能伪造。 

###### DNT 

​        DNT：do not track 的缩写，告诉服务器器，浏览器器客户端是否禁⽌止第三⽅方⽹网站追踪。这⼀条主要是用来保护浏览器用户隐私的，通过此功能，⽤户可以检测到跨站跟踪、cookie跟踪等等。 在爬⾍虫时⼀般都是禁⽌的。数字1代表禁⽌止追踪，0代表接收追踪，null代表空置，没有规定。 

###### Connection 

​        请求头的 header字段指的是当 client 浏览器器和 server 通信时对于⻓长链接如何处理理。由于http 请求是⽆无记忆性的，⻓连接指的是在 client 和server 之间建⽴立⼀一个通道，⽅便两者之间进⾏行行多次数据传输，⽽不用来回传输数据。有 close，keep-alive 等⼏几种赋值，close表示不想建⽴长连接，在操作完成后关闭链接。而keep-alive 表示希望保持畅通来回传输数据。 爬⾍一般都建⽴一个⻓链接。 

###### Proxy-Connection 

​        当使⽤代理服务器的时候，这个就指明了代理服务器是否使用⻓链接。但是，数据在从client 到代理理服务器器，和从代理服务器到被请求的服务器器之间如果存在信息差异的话，会造成信息请求不不到，但是在⼤多数情况下，都还是能够成立的。 

###### Pragma 

​        防⽌止⻚页⾯面被缓存, 和 cache-control类似的⼀一个字段，⼀一般爬⾍虫都写成 no-cache。 

###### Cookie 

​        Cookie是 client 请求服务器时，服务器会返回一个键值对的数据给浏览器器，下⼀次浏览器器再访问这个域名下的网页时，就需要携带这些键值对数据，⽤来跟踪浏览器用户的访问前后路径。在爬⾍时，根据前次访问得到 cookie数据，然后添加到下⼀次的访问请求头中。 

###### Host 

访问的服务器器主机名，⽐比如百度的 www.baidu.com。这个值在爬⾍虫时可以从 访问的 URI 中获 得。 

###### If-Modified-Since 

​        只有当所请求的内容在指定的⽇期之后⼜经过修改才返回它，否则返回304。其⽬的是为了提高访问效率。但是在爬⾍时，不设置这个值，⽽在增量爬取时才设置⼀一个这样的值，⽤以更新信息。 

###### Authorization 

​	当客户端接收到来自WEB服务器的 WWW-Authenticate 响应时，该头部来回应⾃己的身份验证信息给WEB服务器。主要是授权验证，确定符合服务器的要求。这个在爬⾍时按需⽽定。 



一个典型的适⽤用于爬⾍虫爬取数据的伪造请求头如下所示:

“Proxy-Connection”: “keep-alive”,
 “Pragma”: “no-cache”,
 “Cache-Control”: “no-cache”,
 “User-Agent”: “Mozilla/5.0 (Windows NT 6.3; WOW64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/52.0.2743.116 Safari/537.36”, 

“Accept”: “texthtml,applicationxhtml+xml,applicationxml;q=0.9,imagewebp,/;q=0.8”, “DNT”: “1”,
 “Accept-Encoding”: “gzip, deflate, sdch”,
 “Accept-Language”: “zh-CN,zh;q=0.8,en-US;q=0.6,en;q=0.4”, 

“Referer”: “https://www.baidu.com/s? wd=%BC%96%E7%A0%81&rsv_spt=1&rsv_iqid=0x9fcbc99a0000b5d7&issp=1&f=8&rsv_ bp=1&rsv_idx=2&ie=utf-8&rqlang=cn&tn=baiduhome_pg&rsv_enter=0&oq=If-None- Match&inputT=7282&rsv_t=3001MlX2aUzape9perXDW%2FezcxiDTWU4Bt%2FciwbikdOL 

QHYY98rhPyD2LDNevDKyLLg2&rsv_pq=c4163a510000b68a&rsv_sug3=24&rsv_sug1=14 &rsv_sug7=100&rsv_sug2=0&rsv_sug4=7283”,
 “Accept-Charset”: “gb2312,gbk;q=0.7,utf-8;q=0.7,*;q=0.7”, 



###### 请求体 (Request Body) 

POST请求体有内容，GET请求体为空 

可以设置Request Header Content-Type中的参数, 如下：

application/x-www-form-urlencoded 表单数据 

multipart/form-data 表单⽂文件上传

 application/json 序列列化json数据
 text/xml xml数据 

###### 响应
响应状态码 (Response Status Code)

![图](/Users/coco/my_wordspace/knowledge/django/images/response_code.png)

​        响应头，其中包含了了服务器器对请求的应答信息，如 Content-Type、Server、Set-Cookie 等， 下⾯将⼀些常用的头信息说明如下:

* Date，标识 Response 产⽣生的时间。
* Last-Modified，指定资源的最后修改时间。

* Content-Encoding，指定 Response 内容的编码。 Server，包含了服务器的信息，名称，版本号等。 

* Content-Type，⽂文档类型，指定了返回的数据类型是什么，如text/html 则代表返回 HTML ⽂文 档，applicationx-javascript 则代表返回 JavaScript ⽂文件，image/jpeg 则代表返回了了图⽚片。 Set-Cookie，设置Cookie，Response Headers 中的 Set-Cookie即告诉浏览器器需要将此内容 放在 Cookies 中，下次请求携带 Cookies 请求。 

* Expires，指定 Response 的过期时间，使⽤用它可以控制代理理服务器器或浏览器器将内容更更新到缓 存中，如果再次访问时，直接从缓存中加载，降低服务器器负载，缩短加载时间。 

###### 响应体 Resposne Body 

​        响应体最重要的当属响应体内容了，响应的正⽂数据都是在响应体中，如请求一个⽹页， 它的响应体就是⽹页的HTML 代码，请求一张图片，它的响应体就是图片的⼆进制数据。所以最主要的数据都包含在响应体中了，我们做爬⾍时请求⽹页后要解析的内容就是解析响应体。 

###### ⽹网⻚页的组成 

html, css, javascript 